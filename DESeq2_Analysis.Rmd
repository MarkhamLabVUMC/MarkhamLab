---
title: "DESeq2 Analysis"
author: "Ananya Nimbalkar"
# date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    #Table of Content
    toc: yes
    number_sections: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

This notebook is going to follow the DESeq2 tutorial that can be found on bioconductor, specifically at: 

https://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#count-matrix-input

Portions of text have been inputted in this markdown notebook.

*Conclusions not provided.

Differential expression analysis is going to be conducted. 

# Data

The data that is going to be used is the counts matrix that was generated using tximport, as well as the metadata that provides details for each of the samples. 

counts_matrix.csv is a file that represents the number of reads (counts) mapped to each gene across various samples. 

10051_NM_metadata.csv includes information about each samples, such as experimental conditions.

A series of dataframes and figures will be produced using DESeq2.

# Necessary Packages

There are several packages that are required for this analysis, and the code to download it will be shown when it is needed to be used. First we can download the DESeq2 package.

```{r message=FALSE}
if (!require("BiocManager", quietly = TRUE))
  install.packages("BiocManager")

BiocManager::install("DESeq2")
```

# Load Data

The counts matrix and metadata need to be read into RStudio to begin the analysis. For the DESeq2 analysis to run, we need to drop the gene ID columns in both files so only the numeric data remains.

```{r message=FALSE}
library("DESeq2")
library(readr)  # for read_csv
```


```{r}
# Load counts matrix
counts_file_path <- "D:/Analysis/counts_matrix.csv"
counts <- read_csv(counts_file_path, col_names = TRUE)
rownames(counts) <- counts$...1 # Replace '...1' with the actual name of the gene ID column if necessary

# Create copy of counts matrix with gene names
counts_with_gene_names <- counts
counts <- counts[,-1] # Drop the gene ID column so that only numeric count data remains

# Load metadata
metadata_file_path <- "D:/Analysis/10051_NM_metadata.csv"
metadata <- read_csv(metadata_file_path)
rownames(metadata) <- metadata$Sample
metadata <- metadata[,-1] # Remove the 'Sample' column after setting it as row names

```

As seen above, a copy of the counts matrix is created with the gene names to be used in future plots such as a heatmap.

## Data Preparation

Both files that were read in need to be in the same format, so the rows and columns need to be lined up. Here, the rows in the metadata are renamed to match the column names in the counts matrix. Then, a check is done to ensure the data is properly aligned.

```{r}
# Rename rownames in metadata to match the column names in counts
rownames(metadata) <- colnames(counts)

# Check that the sample names in the counts matrix and metadata match
stopifnot(all(colnames(counts) == rownames(metadata)))
```

The metadata file contains 7 different types of conditions across the 30 samples. The 'Condition' column of this file can be adjusted to be a factor with specific levels, setting 'Untreated' as the reference level. This is necessary for the differential expression analysis, as it defines the baseline condition against which other conditions will be compared.

```{r}
# which contains the conditions for each sample
metadata$Condition <- factor(metadata$Condition,
                             levels = c("Untreated", "TcdB", "TcsL", "H2O2", "Vehicle", "TcdA", "TcdB+A"))

# Now 'Untreated' is the first level and thus the reference level by default
# If you want to explicitly set it as the reference you can use relevel
metadata$Condition <- relevel(metadata$Condition, ref = "Untreated")
```

# Create DESeqDataSet Object

Now, we can create the DESeqDataSet object, which is the core data structure used by DESeq2 for storing the count data, metadata, and the design formula for the analysis.

'DESeqDataSetFromMatrix', the function used, is a constructor function that creates the object from a matrix of count data. The counts matrix and metadata are provided as the inputs, as well as a design formula that specifies how the counts are expected to vary according to the experimental conditions.

The 'countData' argument expects the matrix of count data. Each row of this matrix represents a gene and each column represents a sample. Here, we use the variable 'counts' which contains this matrix with the gene IDs removed from the columns and is now just a numeric matrix of read counts.

The 'colData' parameter is used to provide metadata associated with the samples. The 'DataFrame(metadata)' part converts 'metadata' into a DataFrame, which is a data structure required by 'DESeq2' for the column data.

The 'design' argument specifies the formula that models how the counts depend on the experimental conditions. In this case, '~ Condition' means the differential expression analysis should be performed with respect to the 'Condition' variable in the metadata. This means that DESeq2 will analyze the count data to identify genes whose expression changes significantly across the different levels of the 'Condition' variable.

```{r}
# Create the DESeqDataSet object
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = DataFrame(metadata),
                              design = ~ Condition) # Replace 'Condition' with the actual condition variable name if different
```

# Initial Plots

Next, we can produce some preliminary plots to determine what data we are working with. 
## Histogram

First, we can plot a histogram that depicts the counts per conditions.

We need to prepare the metadata so the row names of the DataFrame have a standardized format starting with 'sample' followed by a zero-padded numerical identifier, to ensure ease of identification and compatibility.

```{r}
# Set row names of 'metadata' to the 'Sample' column values
rownames(metadata) <- paste0("sample", sprintf("%04d", as.integer(rownames(metadata))))

```

The raw count data of the matrix is extracted from the 'DESeqDataSet' object, 'dds'. This matrix has genes as rows and samples as columns.

```{r}
# Get raw counts from DESeqDataSet object
raw_counts <- counts(dds)
```

A for loop is created, iterating over each unique condition found in the 'metadata' DataFrame. Within the loop, it first identifies the samples that belong to the current condition being iterated over, then subsets the counts matrix to only include columns (samples) corresponding to the current condition.

'gene_counts_sum' sums the counts across all samples for each gene, resulting in a single sum per gene that represents its overall expression level within the current condition.

Using the 'ggplot2' library, a histogram of the summed counts per gene is created for each condition.

```{r message=FALSE}
library(ggplot2)

# Iterate over each unique condition
for (condition in unique(metadata$Condition)) {
  # Subset sample names for the current condition
  samples_in_condition <- rownames(metadata)[metadata$Condition == condition]
  
  # Subset counts for samples in the current condition
  counts_in_condition <- raw_counts[, samples_in_condition]
  
  # Calculate the sum of counts per gene across all samples in the condition
  gene_counts_sum <- rowSums(counts_in_condition)
  
  # Plot histogram of gene counts sum for the current condition
  p <- ggplot(data = data.frame(gene_counts_sum), aes(x = gene_counts_sum)) +
    geom_histogram(bins = 30, fill = "blue", color = "black") + # Adjust bins as needed
    ggtitle(paste("Histogram of gene counts for", condition)) +
    xlab("Sum of counts per gene") +
    ylab("Number of genes") +
    coord_cartesian(xlim = c(0, 1000)) # Use coord_cartesian to set x-axis limits
  
  # Print the plot
  print(p)
}
```

## Line Graph

A line graph that shows the average count per gene for each condition is plotted.

An empty DataFrame is initialized that will store the average count per gene for each condition after computation.

```{r}
# Calculate average count per gene for each condition
average_counts_per_condition <- data.frame()
```

The for loop iterates over each unique condition present in the 'metadata' DataFrame. For each condition, it performs the following steps:

1. Identifies samples that belong to the current condition by matching the condition name in 'metadata' and then subsets the raw count data, 'raw_counts' to include only those samples.

2. Calculates the average count per gene across the samples for the current condition using 'rowMeans()'. This gives a measure of the central tendency of expression levels for each gene within the condition.

For each condition, a temporary DataFrame called 'condition_data' is created, where it consists of 3 columns: a gene identifier 'Gene', the average count for that gene 'AverageCount', and the condition name 'Condition'. Note the gene identifier is a sequence of numbers from 1 to the number of genes, which are the rows in 'raw_counts'.

This DataFrame is appended to the 'average_counts_per_condition' DataFrame.

```{r}
for (condition in unique(metadata$Condition)) {
  samples_in_condition <- rownames(metadata)[metadata$Condition == condition]
  counts_in_condition <- raw_counts[, samples_in_condition]
  
  # Calculate the average count per gene
  average_counts <- rowMeans(counts_in_condition)
  
  # Prepare a data frame for plotting
  condition_data <- data.frame(Gene = 1:nrow(raw_counts), 
                               AverageCount = average_counts, 
                               Condition = condition)
  average_counts_per_condition <- rbind(average_counts_per_condition, condition_data)
}
```

'ggplot2' is used to create a line plot of the average counts per gene for each condition. The x-axis represents genes, labeled by their order of appearance in the dataset. The y-axis shows the average count per gene. Each condition is differentiated by a different color. The line graph is saved as 'average_gene_counts_by_condition.png'.

```{r}
# Open a PNG device
png("D:\\Analysis\\average_gene_counts_by_condition.png", width = 800, height = 600)

# Plot
ggplot(average_counts_per_condition, aes(x = Gene, y = AverageCount, color = Condition)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Average Gene Counts by Condition", x = "Gene (ordered by appearance)", y = "Average Count") +
  scale_color_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\average_gene_counts_by_condition.png")
```

# Differential Expression Analysis

To do the differential expression analysis, we first have to pre-filter in order to remove genes with low read counts across samples. This is because genes with very low counts are unlikely to be statistically significant, and their inclusion can increase multiple testing burden and reduce the overall power to detect differentially expressed genes.

We set the smallest group size for filtering to 3 and create a logical matrix where entires are 'TRUE' if the count is 10 or more and 'FALSE' if otherwise. The 'dds' variable subsets the 'DESeqDataSet' object, keeping only the genes (rows) that passed the pre-filtering criteria.

```{r}
# Pre-filtering
smallestGroupSize <- 3
keep <- rowSums(counts(dds) >= 10) >= smallestGroupSize
dds <- dds[keep,]
```

After the pre-filtering, the differential expression analysis is performed using the DESeq2 pipeline.

DESeq(dds) estimates size factors, to account for differences in sequencing depth across samples, estimates dispersion values for each gene, and then tests for differential expression. The function returns a modified 'DESEqDataSet' object including the results of the analysis. 'res' extracts the results of the differential expression analysis from the 'DESeqDataSet' object. This includes log2 fold changes, p-values, and adjusted p-values for each gene. The results are then saved as a .csv file titled 'results_table'.

```{r}
# Differential Expression Analysis
# Run the DESeq pipeline
dds <- DESeq(dds)
res <- results(dds)
res

write.csv(as.data.frame(res), 
          file="D:\\Analysis\\results_table.csv")

```


## Log Fold Change

A Log Fold Change (LFC) can be performed, as it is useful for visualization and ranking of genes. The package 'apeglm' is needed because it is an advanced statistical package designed for shrinking log fold changes in high-throughput biological data, improving stability and interpretability.

```{r message=FALSE}
# Install apeglm for log fold change below
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("apeglm")
```

Here, we identify the coefficient to be "Condition_TcdB.A_vs_Untreated", for which LFC shrinkage will be applied. This is done by finding the position of this contrast in the results names of the 'DESeqDataSet' object 'dds' with 'resultsNames(dds)'.

```{r message=FALSE}
library(apeglm)

# 4. LFC
# Log fold change shrinkage for visualization and ranking
resultsNames(dds)
# First, find the position of "Condition_TcdB.A_vs_Untreated" in the resultsNames(dds)
coefPosition <- which(resultsNames(dds) == "Condition_TcdB.A_vs_Untreated")
```

The 'lfcShrink' function is then called on the 'dds' object, specifying the coefficient position of the contrast of interest and the shrinkage method.

LFC shrinkage methods like 'apeglm' are designed to provide more precise and reliable estimates of fold changes, particularly when dealing with noisy data.

The result is then stored in 'resLFC', which contains the shrunken log2fold changes among other statistics for each gene. This is saved as 'results_table_LFC.csv'.

```{r}
# Now use this position with lfcShrink
resLFC <- lfcShrink(dds, coef=coefPosition, type="apeglm")
resLFC

write.csv(as.data.frame(resLFC), 
          file="D:\\Analysis\\results_table_LFC.csv")
```

## Speed-up and Parallelization Thoughts

The above steps usually take less than 30 seconds to run. However, parallelized computation can be used to speed up the process. We need to install 'BiocParallel', which facilitates parallel computing across Bioconductor packages.

```{r message=FALSE}
# 5. Speed-up and parallelization thoughts
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("BiocParallel")
```

Then we can register a parallel backend using 'register(SnowParam(4))'. 'SnowParam' is suggested for Windows systems, specifying that 4 cores should be used for parallel processing. This setup allows subsequent operations that are capable of parallelizations to run more efficiently by utilizing multiple cores. If using a Mac, 'MulticoreParam' will work.

```{r message=FALSE}
library("BiocParallel")

# For windows, use SnowParam, not MulticoreParam: register(MulticoreParam(4))
register(SnowParam(4))

```

## p-values & Adjusted p-values

The results, 'res', can be ordered by the smallest p-value, to help quickly identify the most statistically significant changes in gene expression.

A summary of 'res' is printed, providing an overview of the analysis results, and then it is saved as 'summarized_results.csv'.

```{r}
# 6. p-values & adjusted p-values
resOrdered <- res[order(res$pvalue),]

summary(res)

write.csv(as.data.frame(res), 
          file="D:\\Analysis\\summarized_results.csv")
```

The number of genes that have an adjusted p-value less than 0.1 can be calculated. Adjusted p-values are used to control the False Discovery Rate (FDR), and counting genes below a certain FDR threshold helps quantify the number of findings considered statistically significant.

```{r}
# Shows how many adjusted p-values were less than 0.1
sum(res$padj < 0.1, na.rm=TRUE)
```

The results can be further filtered so only those with an adjusted significance value of 0.05 are extracted. These results are saved as 'summarized_results_pvalue_cutoff.csv'.

```{r}
res05 <- results(dds, alpha=0.05)
summary(res05)

write.csv(as.data.frame(res05), 
          file="D:\\Analysis\\summarized_results_pvalue_cutoff.csv")
```

Lastly, we calculate how many genes meet the criterion of having an adjusted p-value less than 0.05.

```{r}
sum(res05$padj < 0.05, na.rm=TRUE)

```

## Independent Hypothesis Weighting

Independent Hypothesis Weighting (IHW) is a method that improved power in multiple hypothesis testing by assigning different weights to each test based on covariates that affect the power of the tests but are independent of the test outcomes.

We need to install the IHW package in order to proceed.

```{r message=FALSE}
# 7. Independent hypothesis weighting
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("IHW")
```

IHW is run with DESeq2, which obtains the results of differential expression analysis while applying the IHW methof. The 'filterFun=ihw' argument specifies that IHW should be used for adjusting p-values. The summary of this is printed, providing an overview of the number of genes found significant under various thresholds. It is saved as 'summarized_results_IHW.csv'.

```{r message=FALSE}
library("IHW")
resIHW <- results(dds, filterFun=ihw)
summary(resIHW)

write.csv(as.data.frame(resIHW), 
          file="D:\\Analysis\\summarized_results_IHW.csv")
```

We can calculate the number of genes with an adjusted p-value below 0.1, indiciating statistical significance at this threshold, and then retrieve details of the IHW analysis.

```{r}
sum(resIHW$padj < 0.1, na.rm=TRUE)
metadata(resIHW)$ihwResult
```

# Visual Exploration of Results

Up until now, besides the preliminary plots, the results were all numeric. Plots can be produced that showcase these findings.

## MA-plot

MA-plots are a type of scatter plot used in bioinformatics to display the relationship between the magnitude of gene expression changes and the average expression levels across conditions. It plots the log ratio (M, for minus) against the mean average (A, for arthimetic mean) of the intensities of 2 conditions on a log scale. For RNA-seq data, the M values typically represent log2 fold changes between 2 conditions, indiciating how much more or less a gene is expressed relative to a reference. The A values represent average expression levels across those conditions.

We can first plot the raw unshrunken log2 fold changes from the differential expression analysis, from a range of -2 to 2. Points will be colored blue if the adjusted p-value is less than 0.1. Points that fall out of the window are plotted as open triangles, facing up or down.

```{r}
# 8. Exploring and exporting results
# log2 fold changes attributable to a given variable 
#over the mean of normalized counts for all the samples 
# in the DESeqDataSet
# Open a PNG device
png("D:\\Analysis\\MAplot.png", width = 800, height = 600)

plotMA(res, ylim=c(-2,2))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\MAplot.png")
```

An MA-plot of of the log2 fold changes that have been adjusted using a shrinkage estimator, provided by the 'apeglm' package, can be created. Shrinkage methods are used to improve the estimates of fold changes, especially for genes with low counts of high variability, by borrowing information across genes. Once again, the range is specified from -2 to 2, allowing for a direct comparison with the raw fold change plot to see how shrinkage affects the distribution of fold changes.

```{r}
# Open a PNG device
png("D:\\Analysis\\MAplot_Shrunken_log2.png", width = 800, height = 600)

# MA-plot for the shrunken log2 fold changes
plotMA(resLFC, ylim=c(-2,2))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\MAplot_Shrunken_log2.png")
```

### Alternative Shrinkage Estimators

There are different types of shrinkage estimators that can be used. We have been using 'apeglm', which is the default estimator. However, the other types are 'ashr' and 'normal'. For more details, please refer to the bioconductor tutorial.

We list all possible constrasts that have been set up in the 'DESeqDataSet' object 'dds'.

```{r}
resultsNames(dds)
```

The 'ashr' package is installed.

```{r message=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("ashr")
```

We then apply the other 2 LFC shrinkage methods to the same coefficient, 'Condition_TcdB_vs_Untreated', because we are interested in treated vs. untreated. 

'normal' uses a normal prior for shrinkage. This method assumes the LFCs follow a normal distribution.

'ashr' applies adaptive shrinkage. It is designed to adaptively estimate the distribution of effect sizes, potentially providing more accurate shrinkage for datasets with heterogeneous effect sizes or where many effects are truly zero.

```{r}
# because we are interested in treated vs untreated, we set 'coef=2'
# For our data, means Condition_TcdB_vs_Untreated
resNorm <- lfcShrink(dds, coef=2, type="normal")
resAsh <- lfcShrink(dds, coef=2, type="ashr")
```

Each of the MA-plots are then plotted, displaying the log2 fold changes against the average expression levels, highlighting the impact of each shrinkage method on the stability and distribution of LFC estimates.

```{r}
# Open a PNG device
png("D:\\Analysis\\alternative_shrinkage_MAplot.png", width = 800, height = 600)

par(mfrow=c(1,3), mar=c(4,4,2,1))
xlim <- c(1,1e5); ylim <- c(-3,3)

plotMA(resLFC, xlim=xlim, ylim=ylim, main="apeglm")

plotMA(resNorm, xlim=xlim, ylim=ylim, main="normal")

plotMA(resAsh, xlim=xlim, ylim=ylim, main="ashr")

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\alternative_shrinkage_MAplot.png")
```

## Plot Counts

As highlighted in the tutorial, it is also useful to examine the counts of reads for a single gene across the groups. We can use the function 'plotCounts', which normalizes the counts by estimated size factors and adds a pseudocount of 1/2 to allow for log scale plotting.

We find the index of the gene with the smallest adjusted p-value in the results table 'res'. This means the gene chosen is the one considered most significantly differentially expressed across the conditions tested, based on the statistical analysis performed by 'DESeq2'. The 'intgroup="Condition"' parameter specifies the counts should be grouped by the experimental condition, which is essential for comparing the gene's expression levels across different treatment or states. The created plot shows the gene with the lowest adjusted p-value and its count data across diferent conditions specified in the 'dds' object.

```{r}
# Open a PNG device
png("D:\\Analysis\\PlotCounts.png", width = 800, height = 600)

plotCounts(dds, gene=which.min(res$padj), intgroup="Condition")

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\PlotCounts.png")
```

The same plot can be produced but with more customized settings, using 'ggplot2'.

```{r}
# Open a PNG device
png("D:\\Analysis\\PlotCountsCustomized.png", width = 800, height = 600)

d <- plotCounts(dds, gene=which.min(res$padj), intgroup="Condition", 
                returnData=TRUE)
library("ggplot2")
ggplot(d, aes(x=Condition, y=count)) + 
  geom_point(position=position_jitter(w=0.1,h=0)) + 
  scale_y_log10(breaks=c(25,100,400))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\PlotCountsCustomized.png")
```

## Results Columns

More information regarding the results columns can be found, using the 'mcols' function, which retrieves the metadata columns associated with the result object 'res'.

The objects 'resOrdered' and 'res' are saved to a .csv file for viewing purposes.

```{r}
mcols(res)$description

write.csv(as.data.frame(resOrdered), 
          file="D:\\Analysis\\condition_treated_results.csv")

resSig <- subset(resOrdered, padj < 0.1)
resSig

write.csv(as.data.frame(resSig), 
          file="D:\\Analysis\\condition_treated_results_pvalue.csv")
```

# Data Transformations & Visualizations

Using all of the data, we can transform and visualize it to see the differences between various transformation functions.

## Count Data Transformations

The raw output of the RNA-Seq data can be transformed using Variance Stabilizing Transformation (VST) and Regularized Log Transformation (RLT). VST is designed to stabilize the variance across the range of mean values, which is useful when dealing with data that exhibits different levels of sequencing depth across samples. RLT applies a shrinkage estimator the the logarithms of count data to reduce the variability of log-transformed counts, particularly beneficial for low-count genes.

The 'blind=FALSE' argument specifies to use the experimental design information in the transformation.

```{r}
# Data Transformations & Visualization
# Count Data Transformations
# Extracting Transformed Values
vsd <- vst(dds, blind=FALSE)
rld <- rlog(dds, blind=FALSE)
head(assay(vsd), 3)

write.csv(as.data.frame(assay(vsd)), 
          file="D:\\Analysis\\assay_vsd.csv")
```

## Transformed Standard Deviation Plots

To evaluate the effectiveness of different normalization and transformation techniques, 'meanSDPlot' can be produced. Here, we look at 3 types of transformations: normal, variance-stabilized, and regularized log-transformed data.

The 'vsn' and 'hexbin' packages need to be installed for variance stabilization and data visualization respectively. 

```{r, message=FALSE}
# Effects of Transformations on Variance
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("vsn")

if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("hexbin")
```

Then, we can apply a normal transformation to the 'dds' dataset, which takes the logarithm base 2 of the count data incremented by one. This helps handle zeroes and stabilizes the variance by moderating the influence of high-count genes.

```{r}
# this gives log2(n + 1)
ntd <- normTransform(dds)
```

The meanSdPlots are plotted now, for each of the 3 transformations. By plotting mean values against their standard deviations, we can visually see if the transformation reduces variability in a way that is proportional across the range of expression levels. This is crucial for ensuring that downstream analyses like differential expression are reliable and not biased by technical artifacts in the data. The objective is to achieve homoscedasticity, where the variance is approximately constant across all levels of gene expression, which improves the robustness of statistical tests used later in the analysis pipeline.

```{r}
library("vsn")

# Open a PNG device
png("D:\\Analysis\\MeanSdPlot_ntd.png", width = 800, height = 600)

meanSdPlot(assay(ntd))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\MeanSdPlot_ntd.png")

# Open a PNG device
png("D:\\Analysis\\MeanSdPlot_vsd.png", width = 800, height = 600)

meanSdPlot(assay(vsd))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\MeanSdPlot_vsd.png")

# Open a PNG device
png("D:\\Analysis\\MeanSdPlot_rld.png", width = 800, height = 600)

meanSdPlot(assay(rld))

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\MeanSdPlot_rld.png")
```

## Heatmap of Counts Matrix

For the counts matrix, a heatmap is one of the most informative plots that can be created. This type of visualization is commonly used in genomic data analysis to visually assess patterns of expression across different conditions or treatments.

We need the 'pheatmap' package to draw heatmaps. This package in particular popular in the bioinformatics community due to its flexibility and features tailored to genomic data.

```{r, message=FALSE}
# Heatmap of Count Matrix
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install("pheatmap")
```

We obtain the normalized counts from the 'dds' object and compute the mean for each gene across all samples. Then, we select the top 20 genes to plot.

```{r}
# Displays top 20 genes with highest normalized counts
select <- order(rowMeans(counts(dds,normalized=TRUE)),
                decreasing=TRUE)[1:20]
```

We can create a DataFrame that selects the 'Condition' and 'Round' columns of the metadata that can be used to annotate the heatmap, providing contextual information about the samples.

```{r}
df <- as.data.frame(colData(dds)[,c("Condition","Round")])
```

The heatmap is then generated for the top 20 genes, using the normalized transformed data. The rows and columns are not clustered.

```{r, echo=TRUE}
library("pheatmap")

# Open a PNG device
png("D:\\Analysis\\Heatmap.png", width = 800, height = 600)


pheatmap(assay(ntd)[select,], cluster_rows=FALSE, show_rownames=FALSE,
         cluster_cols=FALSE, annotation_col=df)

# Close the device
dev.off()

# knitr::include_graphics("D:\\Analysis\\Heatmap.png")
```

```{r, echo=FALSE}
# Redid it as issue when knitting
# This code shows plot
pheatmap(assay(ntd)[select,], cluster_rows=FALSE, show_rownames=FALSE,
         cluster_cols=FALSE, annotation_col=df)
```

Although this heatmap provides various insights, it is more meaningful to annotate it with the top 20 gene names. So, we can create a DataFrame of these gene names, extract it, and append it to the heatmap.

We get the normalized counts and identify the top 20 genes, as done before. Then, we save this into a DataFrame.

```{r}
# Attempting to get gene names and their counts

# Get the normalized counts
norm_counts <- rowMeans(counts(dds, normalized=TRUE))

# Order the genes by their normalized counts
ordered_genes <- order(norm_counts, decreasing=TRUE)

# Get the names of the top 20 genes from the counts matrix with gene names
top_genes <- rownames(counts_with_gene_names)[ordered_genes[1:20]]

# Get the normalized counts of the top 20 genes
top_counts <- norm_counts[ordered_genes[1:20]]

# Create a dataframe with the gene names and their normalized counts
df_top_genes <- data.frame(Gene = top_genes, NormalizedCounts = top_counts)

# Print the dataframe
print(df_top_genes)

write.csv(as.data.frame(df_top_genes), 
          file="D:\\Analysis\\heatmap_findings.csv")
```

Similarly, we generate the heatmap with the annotated gene names.

```{r}
# Heatmap with gene names depicted
# Assuming 'counts_with_gene_names' exists and has gene names in the first column
# Extract gene names using the 'select' indices
gene_names <- rownames(counts_with_gene_names)[select]

# Use 'assay(ntd)' to get the normalized counts for the top 20 genes
normalized_counts_top_genes <- assay(ntd)[select,]

# Assign gene names as row names to the normalized counts matrix
rownames(normalized_counts_top_genes) <- gene_names

# Prepare the annotation data frame for the columns
df <- as.data.frame(colData(dds)[, c("Condition", "Round")])

# Open a PNG device
png("D:\\Analysis\\Heatmap_Highest_Genes.png", width = 800, height = 600)

# Generate the heatmap with gene names displayed
pheatmap(normalized_counts_top_genes, cluster_rows=FALSE, show_rownames=TRUE,
         cluster_cols=FALSE, annotation_col=df)

# Close the device
dev.off()

# knitr::include_graphics("D:\\Analysis\\Heatmap_Highest_Genes.png")
```

```{r, echo=FALSE}
# Heatmap not knitting again, duplicating code to do so
# Generate the heatmap with gene names displayed
pheatmap(normalized_counts_top_genes, cluster_rows=FALSE, show_rownames=TRUE,
         cluster_cols=FALSE, annotation_col=df)
```

To get the exact values of each cell on the heatmap, in this case the number of normalized counts per gene per sample, we convert the matrix into a DataFrame and add the gene names as the first column. This is saved as a .csv file ready to be analyzed in detail.

```{r}
# Convert the matrix to a DataFrame
normalized_counts_df <- as.data.frame(normalized_counts_top_genes)

# Add the gene names as the first column of the DataFrame
normalized_counts_df$Gene <- rownames(normalized_counts_df)

# Rearrange the DataFrame to have 'Gene' as the first column
normalized_counts_df <- normalized_counts_df[, c("Gene", setdiff(names(normalized_counts_df), "Gene"))]
normalized_counts_df <- normalized_counts_df[,-1]
# Now 'normalized_counts_df' is a DataFrame with the desired structure
print(head(normalized_counts_df))

write.csv(as.data.frame(normalized_counts_df), 
          file="D:\\Analysis\\heatmap_findings_per_sample.csv")
```

If you prefer to have the values directly on the heatmap for each cell, the following code can help achieve that. 

```{r}
# Heatmap with values on it
library(tidyr)

# Assuming 'normalized_counts_top_genes' contains the top 20 genes with row names as gene names
# Convert the matrix to a long format for ggplot
data_long <- as.data.frame(normalized_counts_top_genes) %>%
  tibble::rownames_to_column("Gene") %>%
  tidyr::pivot_longer(-Gene, names_to = "Sample", values_to = "Value")

# Open a PNG device
png("D:\\Analysis\\Heatmap_Highest_Genes_Counts.png", width = 800, height = 600)

# Plot heatmap with ggplot2
ggplot(data_long, aes(x = Sample, y = Gene, fill = Value)) +
  geom_tile() + # Create the heatmap tiles
  geom_text(aes(label = sprintf("%.2f", Value)), size = 3) + # Annotate with values
  scale_fill_gradient(low = "blue", high = "red") + # Color gradient
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Improve X labels readability
  labs(fill = "Normalized\nCount") # Legend title

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\Heatmap_Highest_Genes_Counts.png")

# Note: Adjust 'sprintf("%.2f", Value)' to change the format of the numbers shown
```

## PCA Plot

A Principal Component Analysis (PCA) plot shows the samples in the 2D plane spanned by their first two principal components. This is useful for seeing the overall effect of experimental covariates and batch effects. Here, we take a look of Condition and Cells.

```{r}
# Open a PNG device
png("D:\\Analysis\\PCA_Plot_Samples.png", width = 800, height = 600)

# PCA Plot
# Saved as PCA_Plot_Samples
plotPCA(vsd, intgroup=c("Condition", "Cells"))

# Close the device
dev.off()
```


A more customized PCA plot can be made using 'ggplot'.

```{r}
# PCA Plot
# Saved as PCA_Plot_Samples
plotPCA(vsd, intgroup=c("Condition", "Cells"))

# Open a PNG device
png("D:\\Analysis\\PCA_Plot_Samples_Customized.png", width = 800, height = 600)

pcaData <- plotPCA(vsd, intgroup=c("Condition", "Cells"), returnData=TRUE)
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(PC1, PC2, color=Condition, shape=Cells)) +
  geom_point(size=3) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) + 
  coord_fixed()

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\PCA_Plot_Samples_Customized.png")

```

# Variations to Standard Workflow

There are other ways to conduct the workflow, and they will be discussed below.

## Wald Test

The 'dds' object undergoes several transformations to prepare it for differential expression testing. It uses the functions:

'estimateSizeFactors': To estimate size factors used to normalize the counts data across samples, which helps to adjust for differences in sequencing depth or RNA composition among samples.

```{r}
dds <- estimateSizeFactors(dds)
```

'estimateDispersions': To calculate the dispersions which measure how much the counts vary from sample to sample, which is crucial for the statistic testing that follows.

```{r}
dds <- estimateDispersions(dds)
```

'nbinomWaldTest': To perform a Wald test using a negative binomial model to identify differentially expressed genes, which is one of the hypothesis testing methods provided by 'DESeq2'.

```{r}
dds <- nbinomWaldTest(dds)
```

## Interactions

The next steps involve combining different experimental conditions into a single factor and updating the analysis design. Here, 'Condition' and 'Cells' are combined to create a new factor group. This is useful when interactions between these factors are important or when you want to simplify the model by treating each unique combination as a separate group. The design formula of the 'DESeqDataSet' is updated to use this new group factor, implying that the differential expression is to be analyzed across these combined groups rather than separately.

```{r}
# Combining 'Condition' and 'Cells' into a single factor for the analysis
dds$group <- factor(paste0(dds$Condition, dds$Cells))

# Updating the design formula to use the new 'group' factor
design(dds) <- ~ group
```

Finally, 'DESeq2' is run again with the updated design, and the results are extracted for a specific contrast, in this case comparing the combined group TcdANL.902 to H2o2NL.902. The 'group' parameter can be modified to explore various groups.

```{r}
# Running DESeq2 with the updated design
dds <- DESeq(dds)

# Checking the results names, which will help you specify contrasts
resultsNames(dds)

# Check results for particular group
results(dds, name="group_TcdANL.902_vs_H2O2NL.902")
```

## Likelihood Ratio Test

Another hypothesis test 'DESeq2' offers is the Likelihood Ratio Test (LRT). Where the Wald rest uses the estimated standard error of a log2 fold change to test if it is equal to 0, the LRT examines 2 models for the counts: a full model with a limited number of terms, and a reduced model, where some terms of the full model are removed. In essence, this test determines if the increased likelihood of the data using the additional terms in the full model is more than expected if those extra terms are truly 0.

So, here we perform LRT, obtaining the degrees of freedom from the difference between the number of parameters in the 2 models.

```{r}
# Likelihood Ratio Test
dds <- DESeq(dds, test="LRT", reduced=~1)
res <- results(dds)

write.csv(as.data.frame(res), 
          file="D:\\Analysis\\results_table_LRT.csv")
```

# Additional Plots

This final section will produce more plots that can help strengthen previously made conclusions and/or assumptions.

## Boxplot

Another useful visualization is a boxplot of the log-transformed Cook's distances. We retrieve Cook's distances from a list of assay elements in the 'DESeqDataSet' object, 'dds'. Cook's distance is a measure used in statistics to identify influential data points, particularly useful in the context of regression analysis. It can identify genes that have a disproportionate influence on the parameter estimates of the model.

A logarithmic transformation is applied to these distances, converting them to a log scale. This transformation is often used to manage skewed data or to bring large range values closer together, making patterns easier to discern on plots.

```{r}
# Open a PNG device
png("D:\\Analysis\\Cooks_Boxplot.png", width = 800, height = 600)

# Boxplot
# y-axis is log-transformed Cook's distances of the RNA-seq count data.
par(mar=c(8,5,2,2))
boxplot(log10(assays(dds)[["cooks"]]), range=0, las=2)

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\Cooks_Boxplot.png")
```

## Dispersion Plot

A dispersion plot shows the final estimates shrunk from the gene-wise estimates towards the fitted estimates. The amount of shrinkage can be seen here.

```{r}
# Open a PNG device
png("D:\\Analysis\\Dispersion_Plot.png", width = 800, height = 600)

# Dispersion plot
plotDispEsts(dds)

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\Dispersion_Plot.png")
```

## Alternate MA-plots

A series of Ma-plots using different hypotheses concerning the log fold changes (LFC) can be plotted. The 4 different sets of results are:

'greaterAbs': Tests if the absolute log fold change is greater than the threshold.

'lessAbs': Tests if the absolute log fold change is less than the threshold.

'greater': Tests if the log fold change is greater than the threshold.

'less': Tests if the log fold change is less than the threshold.

A threshold of 0.5 is set that specifies the minimum log fold change that is considered significant.

```{r}
# Open a PNG device
png("D:\\Analysis\\altHypothesis_MAplots.png", width = 800, height = 600)

par(mfrow=c(2,2),mar=c(2,2,1,1))
ylim <- c(-2.5,2.5)
resGA <- results(dds, lfcThreshold = 0.5, altHypothesis = "greaterAbs", test="Wald")
resLA <- results(dds, lfcThreshold=.5, altHypothesis="lessAbs", test="Wald")
resG <- results(dds, lfcThreshold=.5, altHypothesis="greater", test="Wald")
resL <- results(dds, lfcThreshold=.5, altHypothesis="less", test="Wald")
drawLines <- function() abline(h=c(-.5,.5),col="dodgerblue",lwd=2)
plotMA(resGA, ylim=ylim); drawLines()
plotMA(resLA, ylim=ylim); drawLines()
plotMA(resG, ylim=ylim); drawLines()
plotMA(resL, ylim=ylim); drawLines()

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\altHypothesis_MAplots.png")
```

## P-Value Histogram

Lastly, the distribution of p-values from the differential expression analysis can be analyzed.

We can get the average expression of genes across samples by calling 'res$baseMean'. 

'metadata(res)$filterThreshold' fetches a predefined threshold from the metadata of the results object 'res'. This threshold determines the minimum average expression level required for a gene to be considered further.

'use' is a logical vector indicating whether each gene’s base mean expression surpasses the specified threshold. It yields 'TRUE' if it does, 'FALSE' otherwise.

```{r}
use <- res$baseMean > metadata(res)$filterThreshold
```

The histogram can be generated for the p-values of genes, separated into 2 groups based on whether their base mean expression passes the filter threshold. We define 50 evenly spaced bins between 0 and 1, indicating increments of 0.02.

```{r}
# Open a PNG device
png("D:\\Analysis\\pvalue_histogram.png", width = 800, height = 600)

h1 <- hist(res$pvalue[!use], breaks=0:50/50, plot=FALSE)
h2 <- hist(res$pvalue[use], breaks=0:50/50, plot=FALSE)
colori <- c(`do not pass`="khaki", `pass`="powderblue")

barplot(height = rbind(h1$counts, h2$counts), beside = FALSE,
        col = colori, space = 0, main = "", ylab="frequency")
text(x = c(0, length(h1$counts)), y = 0, label = paste(c(0,1)),
     adj = c(0.5,1.7), xpd=NA)

# Close the device
dev.off()

knitr::include_graphics("D:\\Analysis\\pvalue_histogram.png")
```

This is a useful visualization tool in RNA-seq and other omics analyses to evaluate the impact of a base expression threshold on the statistical characteristics of the genes studied. The visual comparison between filtered and unfiltered data can provide insights into how such filtering might bias or otherwise affect the results of the analysis.

## Volcano Plots

For this analysis, volcano plots are another good visualization. It provides quick identification of genes with large fold changes that are statistically significant as well.

We do need to rerun the very beginning part of the code that loads all the counts matrix and metadata in, creating the 'dds' and 'res' objects since we made various changes with the above transformations.

```{r}
library("DESeq2")
library(readr)  # for read_csv

# Load counts matrix
counts_file_path <- "D:/Analysis/counts_matrix.csv"
counts <- read_csv(counts_file_path, col_names = TRUE)
rownames(counts) <- counts$...1 # Replace '...1' with the actual name of the gene ID column if necessary
# Create copy of counts matrix with gene names
counts_with_gene_names <- counts
counts <- counts[,-1] # Drop the gene ID column so that only numeric count data remains

# Load metadata
metadata_file_path <- "D:/Analysis/10051_NM_metadata.csv"
metadata <- read_csv(metadata_file_path)
rownames(metadata) <- metadata$Sample
metadata <- metadata[,-1] # Remove the 'Sample' column after setting it as row names

# Rename rownames in metadata to match the column names in counts
rownames(metadata) <- colnames(counts)

# Check that the sample names in the counts matrix and metadata match
stopifnot(all(colnames(counts) == rownames(metadata)))

# which contains the conditions for each sample
metadata$Condition <- factor(metadata$Condition,
                             levels = c("Untreated", "TcdB", "TcsL", "H2O2", "Vehicle", "TcdA", "TcdB+A"))

# Now 'Untreated' is the first level and thus the reference level by default
# If you want to explicitly set it as the reference you can use relevel
metadata$Condition <- relevel(metadata$Condition, ref = "Untreated")


# Create the DESeqDataSet object
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = DataFrame(metadata),
                              design = ~ Condition) # Replace 'Condition' with the actual condition variable name if different

# Differential Expression Analysis
# Run the DESeq pipeline
dds <- DESeq(dds)
res <- results(dds)
res
```

Now to have the volcano maps clearly labeled with the gene names, we need to create the gene mapping like how we did with the heatmap. So, when the volcano plots are actually produced, the gene names will be directly annotated on it.

```{r}
# Need to add gene names to res to label volcano plots

# Assigning row names from counts_with_gene_names to res
rownames(res) <- rownames(counts_with_gene_names)

# Now, create the gene mapping again
res$gene <- counts_with_gene_names$...1  # Adjust the column name as needed

# Check if any gene names are missing after assignment
if (any(is.na(res$gene))) {
  stop("Some gene names could not be found. Please check the data.")
} else {
  message("Gene names successfully merged!")
}

# Check the head of res to ensure correctness
head(res)
```

The first kind of volcano plot we produce is an unlabeled one using the 'EnhancedVolcano' library.

```{r, message=FALSE}
# 1. Unlabeled volcano plot using EnhancedVolcano

# Load EnhancedVolcano if not already loaded
if (!requireNamespace("EnhancedVolcano", quietly = TRUE)) {
  BiocManager::install("EnhancedVolcano")
}
library(EnhancedVolcano)

# Create the volcano plot using EnhancedVolcano
png("D:\\Analysis\\volcano_plot_unlabeled.png", width = 1200, height = 600)
EnhancedVolcano(res,
                lab = res$gene,
                x = 'log2FoldChange',
                y = 'pvalue',
                title = 'Volcano plot',
                pCutoff = 0.05,  # General p-value cutoff for significance highlighting
                FCcutoff = 2,    # General fold change cutoff for significance highlighting
                pointSize = 2.0,
                labSize = 3.0,
                labCol = 'black',
                colAlpha = 0.8,
                drawConnectors = TRUE,
                selectLab = res$pvalue < 0.01 & abs(res$log2FoldChange) > 2.5)  # More stringent criteria for labeling
dev.off()

knitr::include_graphics("D:\\Analysis\\volcano_plot_unlabeled.png")
```

We can now create a labeled volcano plot that shows the gene names if their p-value is less than 0.05 and their fold change is above 2 or below -2.

```{r}
# 2. Labeled volcano plot using EnhancedVolcano

png("D:\\Analysis\\volcano_plot_labeled.png", width = 1200, height = 600)
EnhancedVolcano(res,
                lab = res$gene,
                x = 'log2FoldChange',
                y = 'pvalue',
                title = 'Volcano plot',
                pCutoff = 0.05,  # General p-value cutoff for significance highlighting
                FCcutoff = 2,    # General fold change cutoff for significance highlighting
                pointSize = 2.0,
                labSize = 3.0,
                labCol = 'black',
                colAlpha = 0.8,
                drawConnectors = TRUE)
dev.off()

knitr::include_graphics("D:\\Analysis\\volcano_plot_labeled.png")
```

Lastly, for stylistic purposes, we can create a volcano plot with 'ggplot' to introduce variety in aesthetics.

```{r}
# 3. Unlabeled volcano plot using gg-Plot

# Install and load ggplot2
if (!requireNamespace("ggplot2", quietly = TRUE))
  install.packages("ggplot2")
library(ggplot2)

png("D:\\Analysis\\volcano_plot_ggplot.png", width = 1200, height = 600)
# Prepare data for plotting
volcano_data <- as.data.frame(res)
volcano_data$gene <- rownames(volcano_data)

# Basic volcano plot
ggplot(volcano_data, aes(x = log2FoldChange, y = -log10(pvalue), color = padj < 0.05)) +
  geom_point(alpha = 0.5) +
  scale_color_manual(values = c("grey", "red")) +
  theme_minimal() +
  labs(x = "Log2 Fold Change", y = "-Log10 p-value", title = "Volcano Plot") +
  geom_hline(yintercept = -log10(0.05), linetype = "dashed", color = "blue")
dev.off()

knitr::include_graphics("D:\\Analysis\\volcano_plot_ggplot.png")
```

# Conclusion

This concludes the 'DESeq2' analysis of our data.