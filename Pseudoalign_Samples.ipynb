{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kallisto, version 0.46.2\n"
     ]
    }
   ],
   "source": [
    "!kallisto version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudoalign Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will pseudoalign the samples and map them to a list of genes and list of counts for each gene. The final product will be a dataframe, where the genes are rows, and the columns represents samples 1-30. However, we will test this process with just 1 sample first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Indexing\n",
    "\n",
    "We need to create an index using kallisto. Kallisto reads the sequences from the specified .fna file, then builds an index based on these sequences. The index is a data structure that Kallisto uses later for quickly aligning reads from RNA-Seq data to the transcriptome. The created index is saved as 'output_indexed.idx'. Once this index is built, it can be used for quantifying transcript abundances from the RNA-Seq data using 'kallisto quant', which is the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file /mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/rna.fna\n",
      "[build] k-mer length: 31\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#Create index using kallisto\n",
    "#Took 8 1/2 minutes to run\n",
    "!kallisto index -i \"/mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/output_indexed.idx\" \"/mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/rna.fna\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Quantifying Transcript Abundances\n",
    "\n",
    "The next step is to quantify transcript abundances. We read in the paired-end RNA-Seq FASTQ files for the first sample, which are in FASTQ format that have been compressed with gzip. Kallisto uses the index file specified by '-i' to align the RNA-Seq reads from the FASTQ files. Then it quantifies the abundance of transcripts based on this alignment. The results include estimated counts and other statistics, which are saved in the output directory specified by '-o'. The data is from paired-end sequencing, so kallisto will treat the 2 FASTQ files as paired reads, aligning them in a manner that considers their paired nature. The output is a file called 'abundance.tsv' which contains the estimated transcript abundances, among other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: kallisto index file not found /mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/output_indexed.idx\n",
      "Error: file not found /mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R1_001.fastq.gz\n",
      "Error: file not found /mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R2_001.fastq.gz\n",
      "Error: could not create directory /mnt/d/kallisto\n",
      "\n",
      "Usage: kallisto quant [arguments] FASTQ-files\n",
      "\n",
      "Required arguments:\n",
      "-i, --index=STRING            Filename for the kallisto index to be used for\n",
      "                              quantification\n",
      "-o, --output-dir=STRING       Directory to write output to\n",
      "\n",
      "Optional arguments:\n",
      "    --bias                    Perform sequence based bias correction\n",
      "-b, --bootstrap-samples=INT   Number of bootstrap samples (default: 0)\n",
      "    --seed=INT                Seed for the bootstrap sampling (default: 42)\n",
      "    --plaintext               Output plaintext instead of HDF5\n",
      "    --fusion                  Search for fusions for Pizzly\n",
      "    --single                  Quantify single-end reads\n",
      "    --single-overhang         Include reads where unobserved rest of fragment is\n",
      "                              predicted to lie outside a transcript\n",
      "    --fr-stranded             Strand specific reads, first read forward\n",
      "    --rf-stranded             Strand specific reads, first read reverse\n",
      "-l, --fragment-length=DOUBLE  Estimated average fragment length\n",
      "-s, --sd=DOUBLE               Estimated standard deviation of fragment length\n",
      "                              (default: -l, -s values are estimated from paired\n",
      "                               end data, but are required when using --single)\n",
      "-t, --threads=INT             Number of threads to use (default: 1)\n",
      "    --pseudobam               Save pseudoalignments to transcriptome to BAM file\n",
      "    --genomebam               Project pseudoalignments to genome sorted BAM file\n",
      "-g, --gtf                     GTF file for transcriptome information\n",
      "                              (required for --genomebam)\n",
      "-c, --chromosomes             Tab separated file with chromosome names and lengths\n",
      "                              (optional for --genomebam, but recommended)\n",
      "    --verbose                 Print out progress information every 1M proccessed reads\n"
     ]
    }
   ],
   "source": [
    "#Took 93 minutes to run\n",
    "!kallisto quant -i \"/mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/output_indexed.idx\" -o \"/mnt/d/kallisto\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R1_001.fastq.gz\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R2_001.fastq.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import Data into a Pandas DataFrame\n",
    "\n",
    "We take the 'abundance.tsv' file and and load it into a dataframe so we can inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/ananim/.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ananim/.local/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ananim/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ananim/.local/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ananim/.local/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163/2196393233.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/d/kallisto/abundance.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample_1_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/d/kallisto/abundance.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m sample_1_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/d/kallisto/abundance.tsv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample_1_df = pd.read_csv(\"/mnt/d/kallisto/abundance.tsv\", sep='\\t')\n",
    "sample_1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Manipulation\n",
    "\n",
    "Next, we can select the columns 'target_id' and 'est_counts', which are the raw estimated counts. Then we can set 'target_id' as the index of 'gene_counts' dataframe. We do some renaming of the headers, and we get the desired output for 1 sample. Essentially, we are extracting the gene/transcript IDs and their corresponding expression measures from a larger dataset, setting up a concise dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10897/929896097.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gene_counts.rename(columns={'tpm': 'Sample_1'}, inplace=True)  # or 'est_counts' as per your data\n"
     ]
    }
   ],
   "source": [
    "gene_counts = sample_1_df[['target_id', 'est_counts']]\n",
    "gene_counts.set_index('target_id', inplace=True)\n",
    "gene_counts.rename(columns={'est_counts': 'Sample_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NM_000014.6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000015.3</th>\n",
       "      <td>0.276341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000016.6</th>\n",
       "      <td>3.067990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000017.4</th>\n",
       "      <td>9.473520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000018.4</th>\n",
       "      <td>90.751800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953251.3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953252.3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953253.3</th>\n",
       "      <td>0.098578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953307.2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953308.2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185121 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sample_1\n",
       "target_id             \n",
       "NM_000014.6   0.000000\n",
       "NM_000015.3   0.276341\n",
       "NM_000016.6   3.067990\n",
       "NM_000017.4   9.473520\n",
       "NM_000018.4  90.751800\n",
       "...                ...\n",
       "XR_953251.3   0.000000\n",
       "XR_953252.3   0.000000\n",
       "XR_953253.3   0.098578\n",
       "XR_953307.2   0.000000\n",
       "XR_953308.2   0.000000\n",
       "\n",
       "[185121 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psuedoalignment for all samples\n",
    "\n",
    "We can do the above process for all of the samples now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a list from 1 to 19 and adds 28, 29, 30\n",
    "samples = list(range(1, 20)) + [28, 29, 30] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0001_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0001_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 207,412,414 reads, 107,409,028 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 188.166\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,484 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0002_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0002_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 110,391,707 reads, 55,185,695 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 194.64\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,342 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0003_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0003_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 115,218,212 reads, 24,920,207 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 184.553\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,247 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0004_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0004_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 107,925,296 reads, 55,394,001 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 190.37\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,304 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0005_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0005_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 154,042,287 reads, 83,975,929 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 189.694\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,352 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0006_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0006_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 127,237,972 reads, 68,864,313 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 190.055\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,307 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0007_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0007_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 123,734,157 reads, 65,543,966 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 186.632\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,456 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0008_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0008_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 127,245,780 reads, 65,157,728 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 186.37\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,425 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0009_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0009_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 137,858,908 reads, 65,566,197 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 194.343\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,287 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0010_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0010_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 148,519,131 reads, 89,508,105 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 189.81\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,635 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0011_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0011_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 140,634,955 reads, 80,444,831 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 193.64\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,395 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0012_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0012_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 123,525,737 reads, 70,627,620 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 194.167\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,680 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0013_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0013_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 125,759,430 reads, 75,728,179 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 190.672\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,322 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0014_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0014_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 143,596,065 reads, 84,150,575 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 193.218\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,717 rounds\n",
      "\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 185,121\n",
      "[index] number of k-mers: 142,403,527\n",
      "[index] number of equivalence classes: 657,654\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0015_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0015_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ..."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "samples = list(range(1, 20)) + [28, 29, 30]  # Sample numbers\n",
    "\n",
    "for sample in samples:\n",
    "    sample_str = f\"{sample:04d}\"  # Formats the sample number as four digits\n",
    "\n",
    "    r1_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R1_001.fastq.gz\"\n",
    "    r2_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R2_001.fastq.gz\"\n",
    "\n",
    "    output_dir = f\"/mnt/d/kallisto/sample_{sample_str}\"\n",
    "\n",
    "    if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "        # Run kallisto quant for each sample\n",
    "        !kallisto quant -i \"/mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/output_indexed.idx\" -o \"{output_dir}\" \"{r1_path}\" \"{r2_path}\"\n",
    "    else:\n",
    "        print(f\"Files for Sample {sample_str} not found, skipping...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to process remaining samples as it crashed after finishing sample 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTQ files for Sample 0001 not found, skipping...\n",
      "FASTQ files for Sample 0002 not found, skipping...\n",
      "FASTQ files for Sample 0003 not found, skipping...\n",
      "FASTQ files for Sample 0004 not found, skipping...\n",
      "FASTQ files for Sample 0005 not found, skipping...\n",
      "FASTQ files for Sample 0006 not found, skipping...\n",
      "FASTQ files for Sample 0007 not found, skipping...\n",
      "FASTQ files for Sample 0008 not found, skipping...\n",
      "FASTQ files for Sample 0009 not found, skipping...\n",
      "FASTQ files for Sample 0010 not found, skipping...\n",
      "FASTQ files for Sample 0011 not found, skipping...\n",
      "FASTQ files for Sample 0012 not found, skipping...\n",
      "FASTQ files for Sample 0013 not found, skipping...\n",
      "FASTQ files for Sample 0014 not found, skipping...\n",
      "FASTQ files for Sample 0015 not found, skipping...\n",
      "FASTQ files for Sample 0016 not found, skipping...\n",
      "FASTQ files for Sample 0017 not found, skipping...\n",
      "FASTQ files for Sample 0018 not found, skipping...\n",
      "FASTQ files for Sample 0019 not found, skipping...\n",
      "FASTQ files for Sample 0028 not found, skipping...\n",
      "FASTQ files for Sample 0029 not found, skipping...\n",
      "FASTQ files for Sample 0030 not found, skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "samples = list(range(1, 20)) + [28, 29, 30]  # Sample numbers\n",
    "\n",
    "for sample in samples:\n",
    "    sample_str = f\"{sample:04d}\"  # Formats the sample number as four digits\n",
    "    output_dir = f\"/mnt/d/kallisto/sample_{sample_str}\"\n",
    "    abundance_file = f\"{output_dir}/abundance.tsv\"\n",
    "\n",
    "    if not os.path.exists(abundance_file):  # Check if the abundance file already exists\n",
    "        r1_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R1_001.fastq.gz\"\n",
    "        r2_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R2_001.fastq.gz\"\n",
    "\n",
    "        if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "            # Run kallisto quant for each sample\n",
    "            !kallisto quant -i \"/mnt/d/fastq/GCF_000001405.40/ncbi_dataset/data/GCF_000001405.40/output_indexed.idx\" -o \"{output_dir}\" \"{r1_path}\" \"{r2_path}\"\n",
    "        else:\n",
    "            print(f\"FASTQ files for Sample {sample_str} not found, skipping...\")\n",
    "    else:\n",
    "        print(f\"Output already exists for Sample {sample_str}, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "samples = list(range(1, 20)) + [28, 29, 30]  # Sample numbers\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for sample in samples:\n",
    "    sample_str = f\"{sample:04d}\"\n",
    "    abundance_path = f\"/mnt/d/kallisto/sample_{sample_str}/abundance.tsv\"\n",
    "    \n",
    "    if os.path.exists(abundance_path):\n",
    "        sample_df = pd.read_csv(abundance_path, sep='\\t')\n",
    "        sample_df = sample_df[['target_id', 'est_counts']].rename(columns={'est_counts': f'Sample_{sample_str}'})\n",
    "        sample_df.set_index('target_id', inplace=True)\n",
    "\n",
    "        if combined_df.empty:\n",
    "            combined_df = sample_df\n",
    "        else:\n",
    "            combined_df = combined_df.join(sample_df, how='outer')\n",
    "    else:\n",
    "        print(f\"Abundance file for Sample {sample_str} not found, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_0001</th>\n",
       "      <th>Sample_0002</th>\n",
       "      <th>Sample_0003</th>\n",
       "      <th>Sample_0004</th>\n",
       "      <th>Sample_0005</th>\n",
       "      <th>Sample_0006</th>\n",
       "      <th>Sample_0007</th>\n",
       "      <th>Sample_0008</th>\n",
       "      <th>Sample_0009</th>\n",
       "      <th>Sample_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>Sample_0013</th>\n",
       "      <th>Sample_0014</th>\n",
       "      <th>Sample_0015</th>\n",
       "      <th>Sample_0016</th>\n",
       "      <th>Sample_0017</th>\n",
       "      <th>Sample_0018</th>\n",
       "      <th>Sample_0019</th>\n",
       "      <th>Sample_0028</th>\n",
       "      <th>Sample_0029</th>\n",
       "      <th>Sample_0030</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NM_000014.6</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.6779</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>106.4040</td>\n",
       "      <td>20.8688</td>\n",
       "      <td>11.689100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000015.3</th>\n",
       "      <td>53.0000</td>\n",
       "      <td>21.3756</td>\n",
       "      <td>204.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>26.4979</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>234.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0000</td>\n",
       "      <td>127.0000</td>\n",
       "      <td>133.2920</td>\n",
       "      <td>145.4330</td>\n",
       "      <td>139.0000</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>183.0000</td>\n",
       "      <td>144.251000</td>\n",
       "      <td>126.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000016.6</th>\n",
       "      <td>1111.5300</td>\n",
       "      <td>633.1070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>685.444</td>\n",
       "      <td>941.400000</td>\n",
       "      <td>700.2260</td>\n",
       "      <td>800.0770</td>\n",
       "      <td>1319.2000</td>\n",
       "      <td>877.3860</td>\n",
       "      <td>2593.1300</td>\n",
       "      <td>...</td>\n",
       "      <td>2226.5200</td>\n",
       "      <td>2023.3900</td>\n",
       "      <td>2138.0100</td>\n",
       "      <td>2178.3400</td>\n",
       "      <td>1815.4800</td>\n",
       "      <td>1600.4100</td>\n",
       "      <td>1311.3700</td>\n",
       "      <td>2062.5300</td>\n",
       "      <td>1095.380000</td>\n",
       "      <td>2197.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000017.4</th>\n",
       "      <td>2766.9300</td>\n",
       "      <td>1395.6200</td>\n",
       "      <td>548.174</td>\n",
       "      <td>1393.820</td>\n",
       "      <td>2528.330000</td>\n",
       "      <td>1978.6700</td>\n",
       "      <td>1899.0600</td>\n",
       "      <td>1861.7100</td>\n",
       "      <td>1307.0000</td>\n",
       "      <td>2078.7900</td>\n",
       "      <td>...</td>\n",
       "      <td>1826.9200</td>\n",
       "      <td>2384.5200</td>\n",
       "      <td>2385.2700</td>\n",
       "      <td>2400.4300</td>\n",
       "      <td>2145.7500</td>\n",
       "      <td>1887.3400</td>\n",
       "      <td>3241.2300</td>\n",
       "      <td>1668.9900</td>\n",
       "      <td>1705.860000</td>\n",
       "      <td>1768.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM_000018.4</th>\n",
       "      <td>31658.6000</td>\n",
       "      <td>17213.7000</td>\n",
       "      <td>4179.900</td>\n",
       "      <td>19550.400</td>\n",
       "      <td>29982.600000</td>\n",
       "      <td>22879.0000</td>\n",
       "      <td>24013.5000</td>\n",
       "      <td>22633.2000</td>\n",
       "      <td>30253.7000</td>\n",
       "      <td>35009.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>29471.8000</td>\n",
       "      <td>31795.3000</td>\n",
       "      <td>32138.3000</td>\n",
       "      <td>26845.2000</td>\n",
       "      <td>24289.1000</td>\n",
       "      <td>23880.0000</td>\n",
       "      <td>31656.9000</td>\n",
       "      <td>27760.3000</td>\n",
       "      <td>24063.300000</td>\n",
       "      <td>21014.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953251.3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.9198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953252.3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.510645</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953253.3</th>\n",
       "      <td>65.4392</td>\n",
       "      <td>42.2042</td>\n",
       "      <td>232.735</td>\n",
       "      <td>37.840</td>\n",
       "      <td>29.089400</td>\n",
       "      <td>24.0502</td>\n",
       "      <td>37.6286</td>\n",
       "      <td>38.1789</td>\n",
       "      <td>63.3103</td>\n",
       "      <td>23.9241</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8345</td>\n",
       "      <td>33.6907</td>\n",
       "      <td>27.5614</td>\n",
       "      <td>38.1278</td>\n",
       "      <td>21.1381</td>\n",
       "      <td>40.0857</td>\n",
       "      <td>53.2241</td>\n",
       "      <td>40.7266</td>\n",
       "      <td>44.493600</td>\n",
       "      <td>54.1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953307.2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XR_953308.2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185121 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sample_0001  Sample_0002  Sample_0003  Sample_0004   Sample_0005  \\\n",
       "target_id                                                                       \n",
       "NM_000014.6       0.0000       0.0000        0.000        0.000      0.000000   \n",
       "NM_000015.3      53.0000      21.3756      204.000       40.000     65.000000   \n",
       "NM_000016.6    1111.5300     633.1070        0.000      685.444    941.400000   \n",
       "NM_000017.4    2766.9300    1395.6200      548.174     1393.820   2528.330000   \n",
       "NM_000018.4   31658.6000   17213.7000     4179.900    19550.400  29982.600000   \n",
       "...                  ...          ...          ...          ...           ...   \n",
       "XR_953251.3       0.0000       0.0000        0.000        0.000      0.066334   \n",
       "XR_953252.3       0.0000       0.0000        0.000        0.000      0.000000   \n",
       "XR_953253.3      65.4392      42.2042      232.735       37.840     29.089400   \n",
       "XR_953307.2       0.0000       0.0000        0.000        0.000      0.000000   \n",
       "XR_953308.2       0.0000       0.0000        0.000        0.000      0.000000   \n",
       "\n",
       "             Sample_0006  Sample_0007  Sample_0008  Sample_0009  Sample_0010  \\\n",
       "target_id                                                                      \n",
       "NM_000014.6       0.0000      17.6779       0.0000       0.0000       0.0000   \n",
       "NM_000015.3      26.4979      40.0000      22.0000      86.0000     234.0000   \n",
       "NM_000016.6     700.2260     800.0770    1319.2000     877.3860    2593.1300   \n",
       "NM_000017.4    1978.6700    1899.0600    1861.7100    1307.0000    2078.7900   \n",
       "NM_000018.4   22879.0000   24013.5000   22633.2000   30253.7000   35009.0000   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "XR_953251.3       0.0000       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953252.3       0.0000       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953253.3      24.0502      37.6286      38.1789      63.3103      23.9241   \n",
       "XR_953307.2       0.0000       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953308.2       0.0000       0.0000       0.0000       0.0000       0.0000   \n",
       "\n",
       "             ...  Sample_0013  Sample_0014  Sample_0015  Sample_0016  \\\n",
       "target_id    ...                                                       \n",
       "NM_000014.6  ...       0.0000       0.0000       0.0000       0.0000   \n",
       "NM_000015.3  ...     143.0000     127.0000     133.2920     145.4330   \n",
       "NM_000016.6  ...    2226.5200    2023.3900    2138.0100    2178.3400   \n",
       "NM_000017.4  ...    1826.9200    2384.5200    2385.2700    2400.4300   \n",
       "NM_000018.4  ...   29471.8000   31795.3000   32138.3000   26845.2000   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "XR_953251.3  ...       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953252.3  ...       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953253.3  ...      24.8345      33.6907      27.5614      38.1278   \n",
       "XR_953307.2  ...       0.0000       0.0000       0.0000       0.0000   \n",
       "XR_953308.2  ...       0.0000       0.0000       0.0000       0.0000   \n",
       "\n",
       "             Sample_0017  Sample_0018  Sample_0019  Sample_0028   Sample_0029  \\\n",
       "target_id                                                                       \n",
       "NM_000014.6       0.0000       0.0000     106.4040      20.8688     11.689100   \n",
       "NM_000015.3     139.0000      77.0000     101.0000     183.0000    144.251000   \n",
       "NM_000016.6    1815.4800    1600.4100    1311.3700    2062.5300   1095.380000   \n",
       "NM_000017.4    2145.7500    1887.3400    3241.2300    1668.9900   1705.860000   \n",
       "NM_000018.4   24289.1000   23880.0000   31656.9000   27760.3000  24063.300000   \n",
       "...                  ...          ...          ...          ...           ...   \n",
       "XR_953251.3       0.0000       0.0000       0.0000       0.0000      0.000000   \n",
       "XR_953252.3       0.0000       0.0000       0.0000       0.0000      0.510645   \n",
       "XR_953253.3      21.1381      40.0857      53.2241      40.7266     44.493600   \n",
       "XR_953307.2       0.0000       0.0000       0.0000       0.0000      0.000000   \n",
       "XR_953308.2       0.0000       0.0000       0.0000       0.0000      0.000000   \n",
       "\n",
       "             Sample_0030  \n",
       "target_id                 \n",
       "NM_000014.6       0.0000  \n",
       "NM_000015.3     126.0000  \n",
       "NM_000016.6    2197.4800  \n",
       "NM_000017.4    1768.3700  \n",
       "NM_000018.4   21014.9000  \n",
       "...                  ...  \n",
       "XR_953251.3      28.9198  \n",
       "XR_953252.3       0.0000  \n",
       "XR_953253.3      54.1422  \n",
       "XR_953307.2       1.0000  \n",
       "XR_953308.2       0.0000  \n",
       "\n",
       "[185121 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('/mnt/d/kallisto/pseudoalign_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo Process with Different Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process will be run with a different index now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file /mnt/e/fastq/Homo_sapiens.GRCh38.cdna.all.fa/Homo_sapiens.GRCh38.cdna.all.fa\n",
      "[build] k-mer length: 31\n",
      "[build] warning: clipped off poly-A tail (longer than 10)\n",
      "        from 1525 target sequences\n",
      "[build] warning: replaced 100005 non-ACGUT characters in the input sequence\n",
      "        with pseudorandom nucleotides\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 1233435 contigs and contains 116726086 k-mers \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create index using kallisto\n",
    "#Took 6 1/2 minutes to run\n",
    "!kallisto index -i \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/output_index.idx\" \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/Homo_sapiens.GRCh38.cdna.all.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 207,249\n",
      "[index] number of k-mers: 116,726,086\n",
      "[index] number of equivalence classes: 848,752\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: /mnt/e/20231030 - 10051-NM/10051-NM-0001_S1_L005_R1_001.fastq.gz\n",
      "                             /mnt/e/20231030 - 10051-NM/10051-NM-0001_S1_L005_R2_001.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 207,412,414 reads, 96,941,450 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 174.509\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 1,327 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Took 134 minutes to run\n",
    "!kallisto quant -i \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/output_index.idx\" -o \"/mnt/d/kallisto_Homo_sapiens\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R1_001.fastq.gz\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0001_S1_L005_R2_001.fastq.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code includes sample 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output already exists for Sample 0001, skipping...\n",
      "Output already exists for Sample 0002, skipping...\n",
      "Output already exists for Sample 0003, skipping...\n",
      "Output already exists for Sample 0004, skipping...\n",
      "Output already exists for Sample 0005, skipping...\n",
      "Output already exists for Sample 0006, skipping...\n",
      "Output already exists for Sample 0007, skipping...\n",
      "Output already exists for Sample 0008, skipping...\n",
      "Output already exists for Sample 0009, skipping...\n",
      "Output already exists for Sample 0010, skipping...\n",
      "Output already exists for Sample 0011, skipping...\n",
      "Output already exists for Sample 0012, skipping...\n",
      "Output already exists for Sample 0013, skipping...\n",
      "Output already exists for Sample 0014, skipping...\n",
      "Output already exists for Sample 0015, skipping...\n",
      "Output already exists for Sample 0016, skipping...\n",
      "Output already exists for Sample 0017, skipping...\n",
      "Output already exists for Sample 0018, skipping...\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 207,249\n",
      "[index] number of k-mers: 116,726,086\n"
     ]
    }
   ],
   "source": [
    "#Ran for 2000 minutes before having to stop.\n",
    "import os\n",
    "\n",
    "samples = list(range(1, 31))  # Sample numbers\n",
    "\n",
    "for sample in samples:\n",
    "    sample_str = f\"{sample:04d}\"  # Formats the sample number as four digits\n",
    "    output_dir = f\"/mnt/d/kallisto_Homo_sapiens/sample_{sample_str}\"\n",
    "    abundance_file = f\"{output_dir}/abundance.tsv\"\n",
    "\n",
    "    if not os.path.exists(abundance_file):  # Check if the abundance file already exists\n",
    "        r1_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R1_001.fastq.gz\"\n",
    "        r2_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R2_001.fastq.gz\"\n",
    "\n",
    "        if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "            # Run kallisto quant for each sample\n",
    "            !kallisto quant -i \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/output_index.idx\" -o \"{output_dir}\" \"{r1_path}\" \"{r2_path}\"\n",
    "        else:\n",
    "            print(f\"FASTQ files for Sample {sample_str} not found, skipping...\")\n",
    "    else:\n",
    "        print(f\"Output already exists for Sample {sample_str}, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantification process is unable to run for sample 19 via Python and Jupter Notebook for undetermined reasons. So, the code below will run the algorithm for all samples but sample 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ran for 2000 minutes before having to stop.\n",
    "import os\n",
    "\n",
    "samples = list(range(1, 19)) + [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]  # Sample numbers\n",
    "\n",
    "for sample in samples:\n",
    "    sample_str = f\"{sample:04d}\"  # Formats the sample number as four digits\n",
    "    output_dir = f\"/mnt/d/kallisto_Homo_sapiens/sample_{sample_str}\"\n",
    "    abundance_file = f\"{output_dir}/abundance.tsv\"\n",
    "\n",
    "    if not os.path.exists(abundance_file):  # Check if the abundance file already exists\n",
    "        r1_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R1_001.fastq.gz\"\n",
    "        r2_path = f\"/mnt/d/20231030 - 10051-NM/10051-NM-{sample_str}_S1_L005_R2_001.fastq.gz\"\n",
    "\n",
    "        if os.path.exists(r1_path) and os.path.exists(r2_path):\n",
    "            # Run kallisto quant for each sample\n",
    "            !kallisto quant -i \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/output_index.idx\" -o \"{output_dir}\" \"{r1_path}\" \"{r2_path}\"\n",
    "        else:\n",
    "            print(f\"FASTQ files for Sample {sample_str} not found, skipping...\")\n",
    "    else:\n",
    "        print(f\"Output already exists for Sample {sample_str}, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 19 needs to run in the windows terminal. Below are the commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallisto quant -i \"/mnt/d/fastq/Homo_sapiens.GRCh38.cdna.all.fa/output_index.idx\" -o \"/mnt/d/kallisto_Homo_sapiens/sample_0019\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0019_S1_L005_R1_001.fastq.gz\" \"/mnt/d/20231030 - 10051-NM/10051-NM-0019_S1_L005_R2_001.fastq.gz\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
